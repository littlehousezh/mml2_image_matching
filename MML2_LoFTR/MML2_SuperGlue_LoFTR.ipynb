{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3306b823",
   "metadata": {
    "papermill": {
     "duration": 0.02384,
     "end_time": "2022-06-04T23:28:46.585630",
     "exception": false,
     "start_time": "2022-06-04T23:28:46.561790",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### This notebook is one of my final submissions which had the best private score.\n",
    "### I also tried emsembling DKM and SE2-LoFTR under multiple conditions and multi-stage approaches,but unfortunately those did not work well for me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb81d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/kornia/kornia\n",
    "# !pip install kornia_moons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a531d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pydegensac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2ba084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install base\n",
    "# !pip install props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4c8b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae32d4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: opencv-python-headless<4.3 in /opt/conda/lib/python3.8/site-packages (4.2.0.34)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.8/site-packages (from opencv-python-headless<4.3) (1.22.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install \"opencv-python-headless<4.3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba7f175b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 3.523441,
     "end_time": "2022-06-04T23:29:51.731670",
     "exception": false,
     "start_time": "2022-06-04T23:29:48.208229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from collections import namedtuple\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import kornia\n",
    "from kornia_moons.feature import *\n",
    "import kornia as K\n",
    "import kornia.feature as KF\n",
    "import gc\n",
    "import pydegensac\n",
    "\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# sys.path.append(\"../input/\")\n",
    "# sys.path.append(\"../input/super-glue-pretrained-network\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f3ab136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/asurion_f22_jw/SuperGluePretrainedNetwork-master\n"
     ]
    }
   ],
   "source": [
    "%cd SuperGluePretrainedNetwork-master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b6e4ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.matching import Matching as Matching_SuperGlue\n",
    "from models.utils import (compute_pose_error, compute_epipolar_error,\n",
    "                          estimate_pose, make_matching_plot,\n",
    "                          error_colormap, AverageTimer, pose_auc, read_image,\n",
    "                          rotate_intrinsics, rotate_pose_inplane,\n",
    "                          scale_intrinsics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58457af2",
   "metadata": {
    "papermill": {
     "duration": 0.08776,
     "end_time": "2022-06-04T23:29:51.831978",
     "exception": false,
     "start_time": "2022-06-04T23:29:51.744218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Oct 24 03:02:44 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  A100-SXM4-40GB      On   | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   61C    P0   302W / 400W |  26402MiB / 40537MiB |    100%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  A100-SXM4-40GB      On   | 00000000:0F:00.0 Off |                    0 |\n",
      "| N/A   26C    P0    63W / 400W |    596MiB / 40537MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  A100-SXM4-40GB      On   | 00000000:47:00.0 Off |                    0 |\n",
      "| N/A   25C    P0    57W / 400W |    596MiB / 40537MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  A100-SXM4-40GB      On   | 00000000:4E:00.0 Off |                    0 |\n",
      "| N/A   26C    P0    56W / 400W |    596MiB / 40537MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  A100-SXM4-40GB      On   | 00000000:87:00.0 Off |                    0 |\n",
      "| N/A   41C    P0    59W / 400W |    596MiB / 40537MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  A100-SXM4-40GB      On   | 00000000:90:00.0 Off |                    0 |\n",
      "| N/A   28C    P0    56W / 400W |    596MiB / 40537MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  A100-SXM4-40GB      On   | 00000000:B7:00.0 Off |                    0 |\n",
      "| N/A   28C    P0    57W / 400W |    596MiB / 40537MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  A100-SXM4-40GB      On   | 00000000:BD:00.0 Off |                    0 |\n",
      "| N/A   29C    P0    56W / 400W |    980MiB / 40537MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "WARNING: infoROM is corrupted at gpu 0000:87:00.0\n"
     ]
    }
   ],
   "source": [
    "# Check which GPUs I am assigned to\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "  print('and then re-execute this cell.')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e433aad4",
   "metadata": {
    "papermill": {
     "duration": 0.011849,
     "end_time": "2022-06-04T23:29:51.856081",
     "exception": false,
     "start_time": "2022-06-04T23:29:51.844232",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## General Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee54206f",
   "metadata": {
    "papermill": {
     "duration": 0.050241,
     "end_time": "2022-06-04T23:29:51.919250",
     "exception": false,
     "start_time": "2022-06-04T23:29:51.869009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>batch_id</th>\n",
       "      <th>image_0_id</th>\n",
       "      <th>image_1_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>googleurban;1cf87530;a5a9975574c94ff9a285f58c3...</td>\n",
       "      <td>1cf87530</td>\n",
       "      <td>a5a9975574c94ff9a285f58c39b53d2c</td>\n",
       "      <td>0143f47ee9e54243a1b8454f3e91621a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>googleurban;6ceaefff;39563e58b2b7411da3f06427c...</td>\n",
       "      <td>6ceaefff</td>\n",
       "      <td>39563e58b2b7411da3f06427c9ee4239</td>\n",
       "      <td>0303b05ca0cb46959eac430e4b2472ca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>googleurban;d91db836;81dd07fb7b9a4e01996cee637...</td>\n",
       "      <td>d91db836</td>\n",
       "      <td>81dd07fb7b9a4e01996cee637f91ca1a</td>\n",
       "      <td>0006b1337a0347f49b4e651c035dfa0e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sample_id  batch_id  \\\n",
       "0  googleurban;1cf87530;a5a9975574c94ff9a285f58c3...  1cf87530   \n",
       "1  googleurban;6ceaefff;39563e58b2b7411da3f06427c...  6ceaefff   \n",
       "2  googleurban;d91db836;81dd07fb7b9a4e01996cee637...  d91db836   \n",
       "\n",
       "                         image_0_id                        image_1_id  \n",
       "0  a5a9975574c94ff9a285f58c39b53d2c  0143f47ee9e54243a1b8454f3e91621a  \n",
       "1  39563e58b2b7411da3f06427c9ee4239  0303b05ca0cb46959eac430e4b2472ca  \n",
       "2  81dd07fb7b9a4e01996cee637f91ca1a  0006b1337a0347f49b4e651c035dfa0e  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = 'image-matching-challenge-2022/'\n",
    "\n",
    "test_samples = []\n",
    "with open(f'{src}/test.csv') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    for i, row in enumerate(reader):\n",
    "        # Skip header.\n",
    "        if i == 0:\n",
    "            continue\n",
    "        test_samples += [row]\n",
    "\n",
    "\n",
    "def FlattenMatrix(M, num_digits=8):\n",
    "    '''Convenience function to write CSV files.'''\n",
    "    \n",
    "    return ' '.join([f'{v:.{num_digits}e}' for v in M.flatten()])\n",
    "\n",
    "\n",
    "def load_torch_image(device, fname=None, local_image=None, size=840.0):\n",
    "    # If the image is already in memory\n",
    "    if local_image is None:\n",
    "        img = cv2.imread(fname)\n",
    "    else:\n",
    "        img = np.copy(local_image)\n",
    "        \n",
    "    if size == -1:\n",
    "        scale = 1\n",
    "    else:\n",
    "        scale = float(size) / float(max(img.shape[0], img.shape[1]))\n",
    "    \n",
    "    w = int(img.shape[1] * scale)\n",
    "    h = int(img.shape[0] * scale)\n",
    "    img = cv2.resize(img, (w, h))\n",
    "    img = K.image_to_tensor(img, False).float() /255.0\n",
    "    img = K.color.bgr_to_rgb(img)\n",
    "    \n",
    "    # the scale value here is the new_size / old_size, different from the original SuperGlue \n",
    "    return img.to(device), scale\n",
    "\n",
    "test_samples_df = pd.DataFrame(test_samples, columns=[\"sample_id\", \"batch_id\", \"image_0_id\", \"image_1_id\"])\n",
    "test_samples_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b3724b",
   "metadata": {
    "papermill": {
     "duration": 0.012302,
     "end_time": "2022-06-04T23:29:51.944788",
     "exception": false,
     "start_time": "2022-06-04T23:29:51.932486",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load SuperGlue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07625159",
   "metadata": {
    "papermill": {
     "duration": 3.935084,
     "end_time": "2022-06-04T23:29:55.892835",
     "exception": false,
     "start_time": "2022-06-04T23:29:51.957751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"outdoor\" weights)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "resize = [-1, ] # resize = [-1, ] means no resize\n",
    "# resize = 840\n",
    "resize_float = True\n",
    "\n",
    "config = {\n",
    "    \"superpoint\": {\n",
    "        \"nms_radius\": 4,\n",
    "        \"keypoint_threshold\": 0.005,\n",
    "        \"max_keypoints\": 2048\n",
    "    },\n",
    "    \"superglue\": {\n",
    "        \"weights\": \"outdoor\",\n",
    "        \"sinkhorn_iterations\": 160,\n",
    "        \"match_threshold\": 0.2,\n",
    "    }\n",
    "}\n",
    "matcher_SG = Matching_SuperGlue(config).eval().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26118e82",
   "metadata": {
    "papermill": {
     "duration": 0.01279,
     "end_time": "2022-06-04T23:29:55.921093",
     "exception": false,
     "start_time": "2022-06-04T23:29:55.908303",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load LoFTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d0f594f",
   "metadata": {
    "papermill": {
     "duration": 1.111163,
     "end_time": "2022-06-04T23:29:57.045777",
     "exception": false,
     "start_time": "2022-06-04T23:29:55.934614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "matcher_LoFTR = KF.LoFTR(pretrained=None)\n",
    "matcher_LoFTR.load_state_dict(torch.load(\"loftr_outdoor.ckpt\")['state_dict'])\n",
    "matcher_LoFTR = matcher_LoFTR.to(device).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f4219b",
   "metadata": {
    "papermill": {
     "duration": 0.013039,
     "end_time": "2022-06-04T23:29:57.071505",
     "exception": false,
     "start_time": "2022-06-04T23:29:57.058466",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Helper Functions to extract keypoints and mateches from the two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5ea8620",
   "metadata": {
    "papermill": {
     "duration": 0.043633,
     "end_time": "2022-06-04T23:29:57.128446",
     "exception": false,
     "start_time": "2022-06-04T23:29:57.084813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_keypoints_with_conf_LoFTR(image_1, image_2, matcher, img_resize=840.0, conf_th=[0.75, 0.5, 0.25, 0], num_keypoints=1000, take_all=False):\n",
    "                          \n",
    "    # the scale value here is the new_size / old_size, different from SuperGlue, to make it the same, take the inverse\n",
    "    image_1_tensor, scale_1 = load_torch_image(device, fname=None, local_image=image_1, size=img_resize)\n",
    "    image_2_tensor, scale_2 = load_torch_image(device, fname=None, local_image=image_2, size=img_resize)\n",
    "    scale_1 = float(1.0 / float(scale_1))\n",
    "    scale_2 = float(1.0 / float(scale_2))\n",
    "    \n",
    "    input_dict = {\"image0\": K.color.rgb_to_grayscale(image_1_tensor), \n",
    "                  \"image1\": K.color.rgb_to_grayscale(image_2_tensor)}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        correspondences = matcher(input_dict)\n",
    "        \n",
    "    mkpts0_LoFTR = correspondences['keypoints0'].cpu().numpy()\n",
    "    mkpts1_LoFTR = correspondences['keypoints1'].cpu().numpy()\n",
    "    conf = correspondences['confidence'].cpu().numpy()\n",
    "    # print(\"initial number of LoFTR points: \" + str(len(mkpts0_LoFTR)))\n",
    "    \n",
    "    if take_all == True:\n",
    "        return mkpts0_LoFTR, mkpts1_LoFTR, np.mean(conf), 0, scale_1, scale_2\n",
    "    \n",
    "    # Create bins of points according to confidence thresholds\n",
    "    mkpts0_LoFTR_conf_0 = mkpts0_LoFTR[conf > conf_th[0]]\n",
    "    mkpts1_LoFTR_conf_0 = mkpts1_LoFTR[conf > conf_th[0]]\n",
    "    mkpts0_LoFTR_conf_1 = mkpts0_LoFTR[conf > conf_th[1]]\n",
    "    mkpts1_LoFTR_conf_1= mkpts1_LoFTR[conf > conf_th[1]]\n",
    "    mkpts0_LoFTR_conf_2 = mkpts0_LoFTR[conf > conf_th[2]]\n",
    "    mkpts1_LoFTR_conf_2 = mkpts1_LoFTR[conf > conf_th[2]]\n",
    "    mkpts0_LoFTR_all = mkpts0_LoFTR[conf >= conf_th[3]]\n",
    "    mkpts1_LoFTR_all = mkpts1_LoFTR[conf >= conf_th[3]]\n",
    "    \n",
    "    # Select the confidence threshold\n",
    "    num_bin_1 = len(mkpts0_LoFTR_conf_0)\n",
    "    num_bin_2 = len(mkpts0_LoFTR_conf_1) - num_bin_1\n",
    "    num_bin_3 = len(mkpts0_LoFTR_conf_2) - num_bin_2 - num_bin_1\n",
    "    num_bin_4 = len(mkpts0_LoFTR_all) - num_bin_3 - num_bin_2 - num_bin_1\n",
    "    \n",
    "    largest_bin_index = np.argmax(np.array([num_bin_1, num_bin_2, num_bin_3, num_bin_4]))\n",
    "    conf_th_final = conf_th[largest_bin_index]\n",
    "    \n",
    "    mkpts0_LoFTR_final = mkpts0_LoFTR[conf > conf_th_final]\n",
    "    mkpts1_LoFTR_final = mkpts1_LoFTR[conf > conf_th_final]\n",
    "    conf_mean = np.mean(conf[conf > conf_th_final])\n",
    "    \n",
    "    if len(mkpts0_LoFTR_final) <= 7:\n",
    "        mkpts0_LoFTR_final = mkpts0_LoFTR_all\n",
    "        mkpts1_LoFTR_final = mkpts1_LoFTR_all\n",
    "        conf_mean = np.mean(conf)\n",
    "    \n",
    "    if len(mkpts0_LoFTR_final) > num_keypoints:\n",
    "        conf_final = conf[conf > conf_th_final]\n",
    "        conf_argsorted = np.argsort(conf_final)\n",
    "        selected_indices = conf_argsorted[-num_keypoints:]\n",
    "        print(np.min(selected_indices))\n",
    "        mkpts0_LoFTR_final = mkpts0_LoFTR_final[selected_indices]\n",
    "        mkpts1_LoFTR_final = mkpts1_LoFTR_final[selected_indices]\n",
    "        \n",
    "    print(\"final number of LoFTR points: \" + str(len(mkpts1_LoFTR_final)))\n",
    "    return mkpts0_LoFTR_final, mkpts1_LoFTR_final, conf_mean, conf_th_final, scale_1, scale_2\n",
    "\n",
    "\n",
    "def get_keypoints_with_conf_SG(image_fpath_0, image_fpath_1, matcher, resize, resize_float, conf_th=[0.75, 0.5, 0.25, 0], take_all=False):\n",
    "    \n",
    "    # scale = original_size / new_size, different from the original SuperGlue. \n",
    "    image_0, inp_0, scales_0 = read_image(image_fpath_0, device, resize, 0, resize_float)\n",
    "    image_1, inp_1, scales_1 = read_image(image_fpath_1, device, resize, 0, resize_float)\n",
    "\n",
    "    input_dict = {\"image0\": inp_0, \"image1\": inp_1}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred_SG = matcher(input_dict)\n",
    "        \n",
    "    pred_SG = {k: v[0].detach().cpu().numpy() for k, v in pred_SG.items()}\n",
    "    kpts0_SG, kpts1_SG = pred_SG[\"keypoints0\"], pred_SG[\"keypoints1\"]\n",
    "    matches_mask_0_SG, conf_0 = pred_SG[\"matches0\"], pred_SG[\"matching_scores0\"]\n",
    "    \n",
    "    valid_0 = matches_mask_0_SG > -1\n",
    "    mkpts0_SG = kpts0_SG[valid_0]\n",
    "    mkpts1_SG = kpts1_SG[matches_mask_0_SG[valid_0]]\n",
    "    conf_0 = conf_0[valid_0]\n",
    "    conf = conf_0\n",
    "    \n",
    "    # print(\"initial number of SG points: \" + str(len(mkpts0_SG)))\n",
    "    if take_all == True:\n",
    "        return mkpts0_SG, mkpts1_SG, np.mean(conf), 0, scale_1, scale_2\n",
    "    \n",
    "    # Create bins of points according to confidence thresholds\n",
    "    mkpts0_SG_conf_0 = mkpts0_SG[conf > conf_th[0]]\n",
    "    mkpts1_SG_conf_0 = mkpts1_SG[conf > conf_th[0]]\n",
    "    mkpts0_SG_conf_1 = mkpts0_SG[conf > conf_th[1]]\n",
    "    mkpts1_SG_conf_1= mkpts1_SG[conf > conf_th[1]]\n",
    "    mkpts0_SG_conf_2 = mkpts0_SG[conf > conf_th[2]]\n",
    "    mkpts1_SG_conf_2 = mkpts1_SG[conf > conf_th[2]]\n",
    "    mkpts0_SG_all = mkpts0_SG[conf >= conf_th[3]]\n",
    "    mkpts1_SG_all = mkpts1_SG[conf >= conf_th[3]]\n",
    "    \n",
    "    # Select the confidence threshold\n",
    "    num_bin_1 = len(mkpts0_SG_conf_0)\n",
    "    num_bin_2 = len(mkpts0_SG_conf_1) - num_bin_1\n",
    "    num_bin_3 = len(mkpts0_SG_conf_2) - num_bin_2 - num_bin_1\n",
    "    num_bin_4 = len(mkpts0_SG_all) - num_bin_3 - num_bin_2 - num_bin_1\n",
    "    \n",
    "    largest_bin_index = np.argmax(np.array([num_bin_1, num_bin_2, num_bin_3, num_bin_4]))\n",
    "    conf_th_final = conf_th[largest_bin_index]\n",
    "    \n",
    "    mkpts0_SG_final = mkpts0_SG[conf > conf_th_final]\n",
    "    mkpts1_SG_final = mkpts1_SG[conf > conf_th_final]\n",
    "    conf_mean = np.mean(conf[conf > conf_th_final])\n",
    "    \n",
    "    if len(mkpts0_SG_final) <= 7:\n",
    "        mkpts0_SG_final = mkpts0_SG_all\n",
    "        mkpts1_SG_final = mkpts1_SG_all\n",
    "        conf_mean = np.mean(conf)\n",
    "\n",
    "    print(\"final number of SG points: \" + str(len(mkpts0_SG_final)))\n",
    "    return mkpts0_SG_final, mkpts1_SG_final, conf_mean, conf_th_final, scales_0, scales_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce74ad4",
   "metadata": {
    "papermill": {
     "duration": 0.012662,
     "end_time": "2022-06-04T23:29:57.154136",
     "exception": false,
     "start_time": "2022-06-04T23:29:57.141474",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Extract keypoints with LoFTR and computer the F matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d5d475f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-contrib-python\n",
    "# !pip install opencv-python-headless==4.6.0.66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ed46a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2.0\n"
     ]
    }
   ],
   "source": [
    "print (cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9255c10c",
   "metadata": {
    "papermill": {
     "duration": 11.876022,
     "end_time": "2022-06-04T23:30:09.044056",
     "exception": false,
     "start_time": "2022-06-04T23:29:57.168034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final number of LoFTR points: 318\n",
      "final number of SG points: 176\n",
      "final number of SG points: 161\n",
      "Running time:  0.7511308193206787  s\n",
      "final number of LoFTR points: 197\n",
      "final number of SG points: 180\n",
      "final number of SG points: 193\n",
      "Running time:  0.7135324478149414  s\n",
      "final number of LoFTR points: 192\n",
      "final number of SG points: 49\n",
      "final number of SG points: 20\n",
      "Running time:  0.6988511085510254  s\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "F_dict = {}\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "num_kpts_LoFTR = 1000\n",
    "conf_th = [0.75, 0.5, 0.25, 0]\n",
    "\n",
    "for i, row in enumerate(test_samples):\n",
    "    sample_id, batch_id, image_1_id, image_2_id = row\n",
    "    \n",
    "    # Load the images.\n",
    "    st = time.time()\n",
    "    image_fpath_1 = f'{src}/test_images/{batch_id}/{image_1_id}.png'\n",
    "    image_fpath_2 = f'{src}/test_images/{batch_id}/{image_2_id}.png'\n",
    "    image_1 = cv2.imread(image_fpath_1)\n",
    "    image_2 = cv2.imread(image_fpath_2)\n",
    "    image_1_tensor, scale = load_torch_image(device, fname=None, local_image=image_1, size=-1)\n",
    "    image_2_tensor, scale = load_torch_image(device, fname=None, local_image=image_2, size=-1)\n",
    "\n",
    "    img1_max_dim = max(image_1.shape[0], image_1.shape[1])\n",
    "    img2_max_dim = max(image_2.shape[0], image_2.shape[1])\n",
    "    max_dim = max(img1_max_dim, img2_max_dim)\n",
    "    \n",
    "    # limit the image size, the input images shouldn't be too big or too small\n",
    "    if max_dim > 1250:\n",
    "        max_dim = 1250\n",
    "    if max_dim < 750:\n",
    "        max_dim = 750\n",
    "\n",
    "    input_dict = {\"image0\": K.color.rgb_to_grayscale(image_1_tensor), \n",
    "                  \"image1\": K.color.rgb_to_grayscale(image_2_tensor)}\n",
    "\n",
    "    # First use LoFTR to get a coarse match \n",
    "    mkpts0_LoFTR_resize2, mkpts1_LoFTR_resize2, conf_mean_LoFTR_resize2, conf_th_LoFTR_resize2, \\\n",
    "            scale_1_LoFTR_resize2, scale_2_LoFTR_resize2 = get_keypoints_with_conf_LoFTR(image_1, \\\n",
    "            image_2, matcher_LoFTR, img_resize=840, conf_th=conf_th, num_keypoints=num_kpts_LoFTR, take_all=False)\n",
    "    conf_th_mean_LoFTR = np.mean([conf_th_LoFTR_resize2])\n",
    "\n",
    "    # Second use SuperGlue to get a coarse match \n",
    "    mkpts0_SG, mkpts1_SG, conf_mean_SG, conf_th_SG, scale_1_SG, scale_2_SG = \\\n",
    "                    get_keypoints_with_conf_SG(image_fpath_1,image_fpath_2, matcher_SG, \\\n",
    "                    resize=[-1, ], resize_float=resize_float, conf_th=conf_th, take_all=False)\n",
    "\n",
    "    mkpts0_SG_resize1, mkpts1_SG_resize1, conf_mean_SG_resize1, conf_th_SG_resize1, scale_1_SG_resize1, \\\n",
    "                    scale_2_SG_resize1 = get_keypoints_with_conf_SG(image_fpath_1,image_fpath_2, matcher_SG, \\\n",
    "                    resize=[max_dim*1.6, ], resize_float=resize_float, conf_th=conf_th, take_all=False)\n",
    "\n",
    "    conf_th_mean_SG = np.mean([conf_th_SG, conf_th_SG_resize1])\n",
    "\n",
    "    # Map the keypoints back according to the image sizes\n",
    "    mkpts0_LoFTR_s2 = mkpts0_LoFTR_resize2 * scale_1_LoFTR_resize2\n",
    "    mkpts1_LoFTR_s2 = mkpts1_LoFTR_resize2 * scale_2_LoFTR_resize2\n",
    "\n",
    "    mkpts0_SG_ns = mkpts0_SG * scale_1_SG\n",
    "    mkpts0_SG_s1 = mkpts0_SG_resize1 * scale_1_SG_resize1\n",
    "    mkpts1_SG_ns = mkpts1_SG * scale_2_SG\n",
    "    mkpts1_SG_s1 = mkpts1_SG_resize1 * scale_2_SG_resize1\n",
    "\n",
    "\n",
    "    mkpts0_combined = np.concatenate((mkpts0_LoFTR_s2, mkpts0_SG_ns, mkpts0_SG_s1), axis=0)                                    \n",
    "    mkpts1_combined = np.concatenate((mkpts1_LoFTR_s2, mkpts1_SG_ns, mkpts1_SG_s1), axis=0)                            \n",
    "\n",
    "    # Get the F-matrix \n",
    "    if len(mkpts0_combined) > 7:\n",
    "        # F, inliers = cv2.findFundamentalMat(mkpts0_combined, mkpts1_combined, cv2.RANSAC, 0.2, 0.99999, 250000)\n",
    "        F, inliers = cv2.findFundamentalMat(mkpts0_combined, mkpts1_combined, cv2.USAC_MAGSAC, 0.2, 0.99999, 250000)\n",
    "        inliers = inliers.squeeze() > 0  \n",
    "        assert F.shape == (3, 3), 'Malformed F?'\n",
    "        F_dict[sample_id] = F  \n",
    "\n",
    "    else:\n",
    "        print(\"zero F matrix\")\n",
    "        F_dict[sample_id] = np.zeros((3, 3))\n",
    "        \n",
    "    gc.collect()\n",
    "    \n",
    "    nd = time.time()   \n",
    "    \n",
    "    if (i < 3):\n",
    "        print(\"Running time: \", nd - st, \" s\")\n",
    "        draw_LAF_matches(\n",
    "        KF.laf_from_center_scale_ori(torch.from_numpy(mkpts0_combined).view(1,-1, 2),\n",
    "                                    torch.ones(mkpts0_combined.shape[0]).view(1,-1, 1, 1),\n",
    "                                    torch.ones(mkpts0_combined.shape[0]).view(1,-1, 1)),\n",
    "\n",
    "        KF.laf_from_center_scale_ori(torch.from_numpy(mkpts1_combined).view(1,-1, 2),\n",
    "                                    torch.ones(mkpts1_combined.shape[0]).view(1,-1, 1, 1),\n",
    "                                    torch.ones(mkpts1_combined.shape[0]).view(1,-1, 1)),\n",
    "        torch.arange(mkpts0_combined.shape[0]).view(-1,1).repeat(1,2),\n",
    "        K.tensor_to_image(image_1_tensor),\n",
    "        K.tensor_to_image(image_2_tensor),\n",
    "        inliers,\n",
    "        draw_dict={'inlier_color': (0.2, 1, 0.2),\n",
    "                   'tentative_color': None, \n",
    "                   'feature_color': (0.2, 0.5, 1), 'vertical': False})\n",
    "\n",
    "        \n",
    "with open('submission.csv', 'w') as f:\n",
    "    f.write('sample_id,fundamental_matrix\\n')\n",
    "    for sample_id, F in F_dict.items():\n",
    "        f.write(f'{sample_id},{FlattenMatrix(F)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04d4010",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 93.51189,
   "end_time": "2022-06-04T23:30:11.098371",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-06-04T23:28:37.586481",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
